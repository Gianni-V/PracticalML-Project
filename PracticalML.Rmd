---
title: "Practical Machine Learning Project"
author: "Gianni-V"
date: "18 octobre 2015"
output: html_document
---
##Synopsis
The purpose of this project is to find a model predicting as precisely as possible the activity quality from activity monitors. The data comes from http://groupware.les.inf.puc-rio.br/har. A random forest model was defined with six influential variables. The model obtains above 98% of correct classifications on the cross-validation set.

##Exploratory data analysis
The data are made of 1 outcome, 159 features and 19622 rows. A simple summary view (in appendix) shows that 2/3 of the features are empty or contain almost NA values thus I focus on the 58 features with data for each row.
```{r, echo=FALSE}
options(scipen=999, digits = 2)
```
```{r, message=FALSE}
library("dplyr")
library("caret")
library("randomForest")
library("doParallel")
library("gridExtra")
set.seed(5345)
```
  
The following vector contains the feature names that I will use:
```{r}
colsSel <- c("user_name","raw_timestamp_part_1","raw_timestamp_part_2","new_window","num_window","roll_belt","pitch_belt","yaw_belt","total_accel_belt","gyros_belt_x","gyros_belt_y","gyros_belt_z","accel_belt_x","accel_belt_y","accel_belt_z","magnet_belt_x","magnet_belt_y","magnet_belt_z","roll_arm","pitch_arm","yaw_arm","total_accel_arm","gyros_arm_x","gyros_arm_y","gyros_arm_z","accel_arm_x","accel_arm_y","accel_arm_z","magnet_arm_x","magnet_arm_y","magnet_arm_z","roll_dumbbell","pitch_dumbbell","yaw_dumbbell","total_accel_dumbbell","gyros_dumbbell_x","gyros_dumbbell_y","gyros_dumbbell_z","accel_dumbbell_x","accel_dumbbell_y","accel_dumbbell_z","magnet_dumbbell_x","magnet_dumbbell_y","magnet_dumbbell_z","roll_forearm","pitch_forearm","yaw_forearm","total_accel_forearm","gyros_forearm_x","gyros_forearm_y","gyros_forearm_z","accel_forearm_x","accel_forearm_y","accel_forearm_z","magnet_forearm_x","magnet_forearm_y","magnet_forearm_z", "classe")
```
  

Before anything else, the training set is split into a sampled training set of 2000 rows and a cross-validation set  with the 17622 remaining rows.
```{r}
origTraining <- read.csv("pml-training.csv")
training <- select_(origTraining, .dots = colsSel)

samp <- sample(nrow(training), 2000)
trainSet <- training[samp,]
cvSet <- training[-samp,]
```
  

First of all, I try to fit a random forest on all the features. The partitioning process of tree classification seems right to manage that data set of which the features seem intermingled and the random forest will avoid overfitting.

After that step, my intention is to find the most important varables and restrict the final model to those ones. By the way, I use a parallel implementation of random forest that run quicker on multicores computers.
```{r, cache=TRUE}
registerDoParallel()
fitRF <- train(classe ~ ., data = trainSet, method = "parRF", prox=T)
```
  

The important variables can be obtained with the **importance** function. It gives the mean decrease in Gini index on a per variable basis, ie an increase in homogeneity/purity.
```{r}
imp <- importance(fitRF$finalModel)
imp <- data.frame(colnames = rownames(imp), imp) %>% arrange(desc(MeanDecreaseGini))
plot(imp$MeanDecreaseGini, ylab = "Mean Gini index decrease")
text(imp[1:6,]$MeanDecreaseGini, labels = imp[1:6,]$colnames, pos = 4)
```

The 6 most influential features are:
```{r}
for(c in imp[1:6,]$colnames) print(c)
```

##Final model
The final model is fitted with those 6 features.
```{r, cache=TRUE}
reducFormula <- as.formula(paste("classe", " ~ ", "`", paste(imp[1:6,]$colnames, collapse="` + `"), "`", sep=""))
fitRF <- train(reducFormula, data = trainSet, method = "parRF", prox=T)
```
  
Finally, it is cross-validated with the cross-validation set:
```{r, message=FALSE}
pred <- predict(fitRF, cvSet)
```
  
Tha accuracy is computed with a contingency table:
```{r}
tab <- table(pred, cvSet$classe)
percentOK <- sum(diag(tab))/sum(tab) * 100
```
The accuracy for that model is **`r percentOK`%**.
  
##Inside the black box
The job is done, but by curiosity, now that we have come to only 6 features, we can plot them and see a bit more clearly the structure in the data set.
```{r, fig.width=9, fig.height=8}
gPts <- geom_point(position = "jitter", alpha = .25)

feat1_3 <- ggplot(data = training, aes_string(x = as.character(imp$colnames[1]), y = as.character(imp$colnames[3]), col = "classe")) + gPts
feat2_3 <- ggplot(data = training, aes_string(x = as.character(imp$colnames[2]), y = as.character(imp$colnames[3]), col = "classe")) + gPts
feat5_4 <- ggplot(data = training, aes_string(x = as.character(imp$colnames[5]), y = as.character(imp$colnames[4]), col = "classe")) + gPts
feat6_4 <- ggplot(data = training, aes_string(x = as.character(imp$colnames[6]), y = as.character(imp$colnames[4]), col = "classe")) + gPts

grid.arrange(feat1_3, feat2_3, feat5_4, feat6_4, nrow = 2, ncol = 2)
```

Obviously, those 6 features succeed quite nicely in displaying patches of homogeneous classes.

##Appendix

###Summary of original training data:
```{r}
summary(origTraining)
```